---
title: AI Agent、MCP 和 Function Calling 原理浅析
date: 2025/04/21
tags:
 - AI
---

AI Agent、MCP、Function Calling 这三个概念在当前的 AI 应用开发，特别是基于大语言模型的 AI 应用开发中，是非常核心且相互关联的。

## 1. AI Agent（人工智能代理）

### 概念
AI Agent 可以理解为一个能够自主感知环境、进行思考（或称推理、决策）、并采取行动以达成特定目标的智能系统。它不仅仅是一个被动响应的模型，更像是一个具有一定自主性的行动者。Agent 的核心在于具有目标导向和行动能力。

### 基本原理（核心循环：感知-思考-行动）

1. **感知**
   - 通过各种方式获取其所处环境的信息
   - 可以是 API 调用数据、读取数据库
   - 或者是直接接收用户的文本和语音输入等

2. **思考**
   - 基于感知到的信息、自身的知识库（通常包括一个核心的大语言模型）以及预设的目标，进行分析、推理和规划
   - 评估当前状态，预测不同行动可能带来的后果
   - 决定下一步应该采取什么行动才能有效地接近或达成目标
   - 这个过程可能涉及复杂的逻辑推导、知识检索、策略选择等

3. **行动**
   - 执行决策出的行动：可以是输出文本/语音回复
   - 调用外部工具或 API（如 function calling）、控制物理设备、修改数据库、发送邮件等

## 2. MCP（Model Context Protocol）：模型上下文协议

### 概念
模型上下文协议是一种开放协议，旨在实现大型语言模型（LLM）应用与外部数据源、工具和服务之间的无缝集成。通过标准化模型与外部资源的交互方式，提升 LLM 应用的功能性、灵活性和可扩展性。通过标准化人工智能应用生态系统中的通信规则，为开发者提供了一个统一、高效且可互操作的开发环境。

### MCP的架构
MCP 就像 USB-C 一样，可以让不同设备能够通过相同的接口连接在一起。
MCP 的架构由四个关键部分组成：

1. 主机（Host）：主机是期望从服务器获取数据的人工智能应用，例如一个集成开发环境（IDE）、聊天机器人等。主机负责初始化和管理客户端、处理用户授权、管理上下文聚合等。
2. 客户端（Client）：客户端是主机与服务器之间的桥梁。它与服务器保持一对一的连接，负责消息路由、能力管理、协议协商和订阅管理等。客户端确保主机和服务器之间的通信清晰、安全且高效。
3. 服务器（Server）：服务器是提供外部数据和工具的组件。它通过工具、资源和提示模板为大型语言模型提供额外的上下文和功能。例如，一个服务器可以提供与Gmail、Slack等外部服务的API调用。
4. 基础协议（Base Protocol）：基础协议定义了主机、客户端和服务器之间如何通信。它包括消息格式、生命周期管理和传输机制等。

### MCP的工作原理
* MCP 通过定义标准化的数据格式和通信协议，实现 LLM 与外部资源的交互
* MCP 使用 JSON-RPC 2.0 作为消息格式，通过标准的请求、响应和通知消息进行通信
* MCP 支持多种传输机制，包括本地的标准输入/输出（Stdio）和基于HTTP的服务器发送事件（SSE）。
* MCP的生命周期包括初始化、运行和关闭三个阶段，确保连接的建立、通信和终止都符合协议规范。

关于更多 MCP 的详细介绍，可参考文章：https://www.runoob.com/np/mcp-protocol.html

## 3.  Function Calling（函数调用）

### 概念
Function Calling 特指在大语言模型（LLM）应用中的一种机制，允许 LLM 识别出用户请求中需要通过外部工具或 API 来完成的部分，并生成结构化的数据（通常是 JSON 格式）来请求调用相应的函数。它弥补了 LLM 本身无法直接与外部世界交互、获取实时信息或执行具体操作的短板。

### 基本原理（典型流程）
1. 定义可用函数: 开发者首先向 LLM 提供一组可用函数的描述。这些描述通常包括：函数名称、函数用途的自然语言描述、函数需要的参数（名称、类型、描述）以及必需参数列表。
2. 用户输入: 用户向 LLM 发出请求，例如：“帮我查一下明天北京的天气怎么样？”
3. LLM 理解与决策: LLM 分析用户请求，并结合之前提供的函数描述，判断是否需要以及需要调用哪个函数来满足请求。在这个例子中，LLM 会识别出需要调用一个查询天气的函数（比如 get_weather）。
4. 生成函数调用参数: LLM 不会直接执行函数，而是输出一个结构化的数据（例如 JSON 对象），指明要调用的函数名以及从用户请求中提取出的参数。例如
```JSON
{
  "function_name": "get_weather",
  "arguments": {
    "city": "北京",
    "date": "明天"
  }
}
```
5. 外部代码执行: 开发者编写的应用程序代码接收到这个 JSON 输出。代码解析这个 JSON，找到对应的 get_weather 函数，并使用提取出的参数（"北京", "明天"）实际执行这个函数（比如调用一个天气 API）。
6. 返回结果给 LLM: 函数执行完成后，外部代码将函数的返回结果（例如，具体的天气信息）发送回 LLM。
7. LLM 生成最终回复: LLM 接收到函数执行的结果，并基于这个结果，生成一个自然语言的回复给用户。例如：“明天的北京天气预计是晴朗，气温 15-25 摄氏度。”

Function Calling 极大地扩展了 LLM 的能力，使其从一个单纯的文本生成器转变为能够驱动行动、与外部系统集成的智能核心。这是构建能够执行实际任务的 AI Agent 的关键技术之一。Agent 的“行动”能力很多时候就是通过 Function Calling 来实现的。

## 总结
* AI Agent 是一个宏观的概念，描述了一个具有感知、思考、行动能力的智能实体。
* Function Calling 是实现 AI Agent（特别是基于 LLM 的 Agent）“行动”能力的一种非常重要的具体技术手段。它让 Agent 能够调用外部工具来完成任务。
* MCP 则是在存在多个 AI Agent 时，用于管理它们之间协作与沟通的机制或框架。一个复杂的系统可能包含多个 Agent，每个 Agent 内部可能使用 Function Calling 来执行任务，而 Agent 之间则通过 MCP 来协同工作。
